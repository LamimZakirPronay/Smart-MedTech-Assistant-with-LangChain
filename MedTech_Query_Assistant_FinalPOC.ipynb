{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b4ce5d-4bdd-4dec-9f7f-7578a812622b",
   "metadata": {},
   "source": [
    "# LangChain-Powered MedTech Assistant Notebook\n",
    "\n",
    "## Overview\n",
    "This notebook implements a LangChain-powered MedTech assistant with the following capabilities:\n",
    "\n",
    "###  Smart Query Classification\n",
    "Automatically categorizes input as one of:\n",
    "- **DB-related**: Searches for known medical innovations.\n",
    "- **Idea**: Recognizes user-proposed MedTech concepts.\n",
    "- **Irrelevant**: Filters out non-MedTech content.\n",
    "\n",
    "###  Semantic Search with FAISS\n",
    "Uses sentence-transformer embeddings and a FAISS vector index to retrieve similar MedTech innovations from a mock database.\n",
    "\n",
    "###  Clarification for Idea Refinement\n",
    "When a user submits a new idea, the assistant:\n",
    "- Retrieves related innovations.\n",
    "- Asks 2–3 clarifying questions to improve the idea.\n",
    "\n",
    "###  LLM-Powered Fallbac k  Answering\n",
    "If a query doesn’t match existing DB entries, the assistant leverages an LLM to provide a helpful general explanation.\n",
    "\n",
    "###  Conversation Memory + Summarization\n",
    "- Tracks chat history using `ConversationBufferMemory`.\n",
    "- Summarizes recent exchanges to provide continuity.\n",
    "\n",
    "of your script automatically?\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71629906-eedc-40c7-8910-784e4a2afc46",
   "metadata": {},
   "source": [
    "### Pre-Requisites \n",
    "\n",
    "We Installed LLAMA3 for  API calls/LLM calls.You can simply run \"ollama run llama3\" in terminal and it should be working fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac17574-3a5d-4ff6-8747-7ef62c2214f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\prona\\anaconda3\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\prona\\anaconda3\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain) (0.3.65)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain-community) (3.9.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain-community) (8.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.14.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\prona\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prona\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\prona\\anaconda3\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\prona\\anaconda3\\lib\\site-packages (3.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community\n",
    "!pip install rapidfuzz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6cd33e-0319-4510-bc2d-2c449650c14a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! Type your query below (type 'exit' to quit).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your Query:  Can you help me with Pulse Meter ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Response ---\n",
      "Here's my step-by-step reasoning and considerations:\n",
      "\n",
      "When considering how to assist with a Pulse Meter, I think about the various aspects that are involved. A pulse meter is typically used to measure a person's heart rate or blood flow in real-time. To provide assistance, I would need to understand what the user means by \"Pulse Meter\". Are they referring to a physical device, such as a wearable fitness tracker or a medical device used in hospitals? Or are they asking about how to read and interpret pulse data from a digital display? Additionally, I would want to know if the user has any specific goals or concerns related to their heart rate or blood flow. For instance, are they trying to monitor their physical activity levels, manage stress, or diagnose a medical condition? By considering these factors, I can provide more tailored and accurate guidance.\n",
      "\n",
      "Now, here's my response:\n",
      "\n",
      "To help you with your Pulse Meter query, I'd like to clarify a few things. Can you please specify what kind of Pulse Meter you're referring to? Are you looking for information on how to use a specific device, or do you have questions about interpreting pulse data? Additionally, are there any specific goals or concerns you have related to your heart rate or blood flow that I can help with? With this information, I'll be happy to provide more targeted assistance.\n",
      "\n",
      "--- Summary So Far ---\n",
      "There is no conversation yet, as the first message from a human user asking for help with \"Pulse Meter\" has just been received. The AI assistant responded by providing a step-by-step reasoning and considerations on how to assist with a Pulse Meter, and then asked clarifying questions to understand the user's query better.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Your Query:  Can you help me with Python Programming ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Response ---\n",
      "Sorry, this assistant only handles MedTech-related queries. Please ask about medical devices, healthcare innovations, or propose an idea in that domain.\n",
      "\n",
      "--- Summary So Far ---\n",
      "The conversation started with a human message asking for help with \"Pulse Meter\". The AI responded by providing a step-by-step reasoning and considerations to understand what the user means by \"Pulse Meter\", which includes clarifying whether it refers to a physical device, digital display, or specific goals/concerns related to heart rate or blood flow. The AI then asked follow-up questions to gather more information from the user.\n",
      "\n",
      "However, the conversation took a turn when the human sent another message asking for help with \"Python Programming\". The AI responded by stating that it only handles MedTech-related queries and does not assist with general programming topics like Python.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from rapidfuzz import fuzz\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "# === Embedding Model ===\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "#Here we are creating  a MOCK Data base so we can show the logic of  when to come for DB and When to seek LLM\n",
    "\n",
    "innovation_db = [\n",
    "    {\"id\": 1, \"title\": \"Smart Pulse Oximeter\", \"description\": \"Measures oxygen saturation and heart rate with smartphone connectivity.\"},\n",
    "    {\"id\": 2, \"title\": \"Portable ECG Monitor\", \"description\": \"A compact device for real-time ECG monitoring at home.\"},\n",
    "    {\"id\": 3, \"title\": \"Wireless Glucometer\", \"description\": \"Measures blood glucose levels and syncs data with cloud platforms.\"},\n",
    "    {\"id\": 4, \"title\": \"Digital Stethoscope\", \"description\": \"Amplifies and records heart and lung sounds digitally.\"},\n",
    "    {\"id\": 5, \"title\": \"AI-Powered Thermometer\", \"description\": \"Uses machine learning to predict fever patterns and trends.\"},\n",
    "    {\"id\": 6, \"title\": \"Wearable Blood Pressure Monitor\", \"description\": \"Continuous BP monitoring via a wrist-worn device.\"},\n",
    "    {\"id\": 7, \"title\": \"Smart Inhaler\", \"description\": \"Tracks asthma medication usage and sends reminders.\"},\n",
    "    {\"id\": 8, \"title\": \"Handheld Ultrasound Scanner\", \"description\": \"Portable ultrasound imaging for bedside diagnostics.\"},\n",
    "    {\"id\": 9, \"title\": \"Remote Fetal Monitor\", \"description\": \"Monitors fetal heart rate and movement remotely during pregnancy.\"},\n",
    "    {\"id\": 10, \"title\": \"Digital Otoscope\", \"description\": \"Captures inner ear images and transmits them for remote diagnosis.\"},\n",
    "    {\"id\": 11, \"title\": \"Smart Nebulizer\", \"description\": \"Delivers aerosol medication with dose tracking and mobile alerts.\"},\n",
    "    {\"id\": 12, \"title\": \"AI-Based Retinal Scanner\", \"description\": \"Detects early signs of diabetic retinopathy through eye scans.\"},\n",
    "    {\"id\": 13, \"title\": \"Connected Spirometer\", \"description\": \"Measures lung function and tracks respiratory performance over time.\"},\n",
    "    {\"id\": 14, \"title\": \"Digital Pill Dispenser\", \"description\": \"Ensures correct medication timing with alerts and tracking.\"},\n",
    "    {\"id\": 15, \"title\": \"Smart IV Pump\", \"description\": \"Adjusts infusion rate based on patient vitals and alerts caregivers.\"},\n",
    "    {\"id\": 16, \"title\": \"Smart Hearing Aid\", \"description\": \"Adapts to environment noise levels and connects to smartphones for customization.\"},\n",
    "    {\"id\": 17, \"title\": \"Smart Contact Lens\", \"description\": \"Measures intraocular pressure and monitors diabetes via tear glucose levels.\"},\n",
    "    {\"id\": 18, \"title\": \"Digital Wound Monitor\", \"description\": \"Uses imaging and sensors to monitor wound healing progress and infection risk.\"},\n",
    "    {\"id\": 19, \"title\": \"Digital X-ray Machine\", \"description\": \"Captures internal bone and organ images using low-dose X-ray radiation for diagnosis.\"}\n",
    "]\n",
    "\n",
    "# === FAISS Index Build ===\n",
    "record_texts = [f\"{rec['title']} {rec['description']}\" for rec in innovation_db]\n",
    "record_embeddings = embedding_model.encode(record_texts, convert_to_numpy=True)\n",
    "index = faiss.IndexFlatL2(record_embeddings.shape[1])\n",
    "index.add(record_embeddings)\n",
    "\n",
    "# For Models we used Local LLAMA3 model.\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "# === Memory ===\n",
    "# Usually memory is needed for context , but having a large K will create issues of computation so we are summarizing the texts  before going forward.\n",
    "\n",
    "buffer_memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# === Summarization Chain ===\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful assistant. Summarize the following conversation so far:\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Summary:\"\"\"\n",
    ")\n",
    "summary_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
    "\n",
    "def get_summary():\n",
    "    history = buffer_memory.chat_memory.messages[-10:]  # Only last 5 user+AI turns\n",
    "    return summary_chain.run(chat_history=history)\n",
    "\n",
    "# === Classifier Chain ===\n",
    "classifier_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a strict classifier assistant. Categorize the user query strictly as one of the following:\n",
    "\n",
    "- DB-related: If the query asks about or searches innovation records or known technologies such as pulse oximeter, pulse meter, ECG monitor, glucometer, digital stethoscope, AI thermometer, blood pressure monitor, smart inhaler, ultrasound scanner, fetal monitor, otoscope, smart nebulizer, retinal scanner, spirometer, pill dispenser, IV pump, hearing aid, contact lens, wound monitor, X-ray machine, or other medical devices and health monitors.\n",
    "\n",
    "- Idea: If the query proposes a new concept or idea to improve a process or product.\n",
    "\n",
    "- Irrelevant: If the query is general knowledge (e.g. what is RAM, history of India), or does not relate to MedTech or innovation.\n",
    "\n",
    "Be strict. Do not guess. Use only the content of the query.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Classification:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "classifier_chain = LLMChain(llm=llm, prompt=classifier_prompt)\n",
    "\n",
    "def classify_query(query: str) -> str:\n",
    "    try:\n",
    "        raw_result = classifier_chain.run(query=query).strip().lower().splitlines()[0]\n",
    "        if \"db\" in raw_result:\n",
    "            return \"db-related\"\n",
    "        elif \"idea\" in raw_result:\n",
    "            return \"idea\"\n",
    "        else:\n",
    "            return \"irrelevant\"\n",
    "    except Exception:\n",
    "        return \"irrelevant\"\n",
    "\n",
    "# === Vector Search ===\n",
    "def vector_db_search(query: str, top_k: int = 3, threshold: float = 0.75):\n",
    "    query_embedding = embedding_model.encode([query], convert_to_numpy=True)\n",
    "    D, I = index.search(query_embedding, top_k)\n",
    "    results = []\n",
    "    for i, dist in zip(I[0], D[0]):\n",
    "        if dist < threshold:\n",
    "            results.append(innovation_db[i])\n",
    "    return results\n",
    "\n",
    "def find_similar_use_cases(idea_text, top_k=3):\n",
    "    return vector_db_search(idea_text, top_k=top_k)\n",
    "\n",
    "# === Clarifying Questions ===\n",
    "clarify_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an innovation expert. Read the idea carefully and generate 2-3 clarifying questions that would help improve it.\n",
    "\n",
    "Idea: {idea}\n",
    "\n",
    "Clarifying Questions:\"\"\"\n",
    ")\n",
    "clarify_chain = LLMChain(llm=llm, prompt=clarify_prompt)\n",
    "\n",
    "def get_clarifying_questions(idea: str) -> str:\n",
    "    return clarify_chain.run(idea=idea).strip()\n",
    "\n",
    "# === General Fallback LLM Answer Chain ===\n",
    "fallback_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"The user asked: {query}\n",
    "    \n",
    "Before providing your final answer, first explain your step-by-step reasoning and considerations to arrive at the answer in a sperate paragraph.Once you hvae\n",
    "provided the reasoning then only provide the response.\n",
    "\n",
    "Provide a helpful and informative response:\"\"\"\n",
    "    \n",
    ")\n",
    "llm_chain = LLMChain(llm=llm, prompt=fallback_prompt)\n",
    "\n",
    "# === Handle Query ===\n",
    "def handle_query(user_query: str) -> str:\n",
    "    category = classify_query(user_query)\n",
    "\n",
    "    if category == \"db-related\":\n",
    "        records = vector_db_search(user_query)\n",
    "        if records:\n",
    "            return \"Innovation DB Records Found:\\n\" + \"\\n\".join(\n",
    "                [f\"- {r['title']}: {r['description']}\" for r in records]\n",
    "            )\n",
    "        else:\n",
    "            return llm_chain.run(query=user_query)\n",
    "\n",
    "    elif category == \"idea\":\n",
    "        similar = find_similar_use_cases(user_query)\n",
    "        response = \"Similar Use Cases:\\n\"\n",
    "        if similar:\n",
    "            response += \"\\n\".join([f\"- {s['title']}: {s['description']}\" for s in similar])\n",
    "        else:\n",
    "            response += \"No similar use cases found.\"\n",
    "\n",
    "        questions = get_clarifying_questions(user_query)\n",
    "        response += \"\\n\\nTo refine your idea, consider these questions:\\n\" + questions\n",
    "        return response\n",
    "\n",
    "    else:\n",
    "        return \"Sorry, this assistant only handles MedTech-related queries. Please ask about medical devices, healthcare innovations, or propose an idea in that domain.\"\n",
    "\n",
    "# === CLI Interaction with Summary ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome! Type your query below (type 'exit' to quit).\")\n",
    "    while True:\n",
    "        user_input = input(\"\\nYour Query: \").strip()\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        if user_input.lower() in {\"help\", \"options\"}:\n",
    "            print(\"You can ask about known MedTech devices, propose an idea, or ask general MedTech questions.\")\n",
    "            continue\n",
    "\n",
    "        buffer_memory.chat_memory.add_user_message(user_input)\n",
    "\n",
    "        reply = handle_query(user_input)\n",
    "\n",
    "        buffer_memory.chat_memory.add_ai_message(reply)\n",
    "\n",
    "        print(\"\\n--- Response ---\")\n",
    "        print(reply)\n",
    "\n",
    "        summary = get_summary()\n",
    "        print(\"\\n--- Summary So Far ---\")\n",
    "        print(summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f94409-af03-4208-99e0-2b6dd5367287",
   "metadata": {},
   "source": [
    "## Response Recieved from the CODE \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Welcome! Type your query below (type 'exit' to quit).\n",
    "\n",
    "Your Query:  Can you help me with Pulse Meter ?\n",
    "\n",
    "--- Response ---\n",
    "Here's my step-by-step reasoning and considerations:\n",
    "\n",
    "When considering how to assist with a Pulse Meter, I think about the various aspects that are involved. A pulse meter is typically used to measure a person's heart rate or blood flow in real-time. To provide assistance, I would need to understand what the user means by \"Pulse Meter\". Are they referring to a physical device, such as a wearable fitness tracker or a medical device used in hospitals? Or are they asking about how to read and interpret pulse data from a digital display? Additionally, I would want to know if the user has any specific goals or concerns related to their heart rate or blood flow. For instance, are they trying to monitor their physical activity levels, manage stress, or diagnose a medical condition? By considering these factors, I can provide more tailored and accurate guidance.\n",
    "\n",
    "Now, here's my response:\n",
    "\n",
    "To help you with your Pulse Meter query, I'd like to clarify a few things. Can you please specify what kind of Pulse Meter you're referring to? Are you looking for information on how to use a specific device, or do you have questions about interpreting pulse data? Additionally, are there any specific goals or concerns you have related to your heart rate or blood flow that I can help with? With this information, I'll be happy to provide more targeted assistance.\n",
    "\n",
    "--- Summary So Far ---\n",
    "There is no conversation yet, as the first message from a human user asking for help with \"Pulse Meter\" has just been received. The AI assistant responded by providing a step-by-step reasoning and considerations on how to assist with a Pulse Meter, and then asked clarifying questions to understand the user's query better.\n",
    "\n",
    "Your Query:  Can you help me with Python Programming ?\n",
    "\n",
    "--- Response ---\n",
    "Sorry, this assistant only handles MedTech-related queries. Please ask about medical devices, healthcare innovations, or propose an idea in that domain.\n",
    "\n",
    "--- Summary So Far ---\n",
    "The conversation started with a human message asking for help with \"Pulse Meter\". The AI responded by providing a step-by-step reasoning and considerations to understand what the user means by \"Pulse Meter\", which includes clarifying whether it refers to a physical device, digital display, or specific goals/concerns related to heart rate or blood flow. The AI then asked follow-up questions to gather more information from the user.\n",
    "\n",
    "However, the conversation took a turn when the human sent another message asking for help with \"Python Programming\". The AI responded by stating that it only handles MedTech-related queries and does not assist with general programming topics like Python.\n",
    "\n",
    "Your Query: \n",
    "↑↓ for history. Search history with c-↑/c-↓\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217bc32e-e6d2-49a8-9360-583a45e65eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
